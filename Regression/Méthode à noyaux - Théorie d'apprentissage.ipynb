{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Théorie apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser la base de données suivante : https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est une base que nous avons vu dans le TP1 de DS,qui concerne le nombre de vélos prêter entre 2011 et 2012 par Capital Bikeshare à Whashington D.C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   instant     731 non-null    int64  \n",
      " 1   dteday      731 non-null    object \n",
      " 2   season      731 non-null    int64  \n",
      " 3   yr          731 non-null    int64  \n",
      " 4   mnth        731 non-null    int64  \n",
      " 5   holiday     731 non-null    int64  \n",
      " 6   weekday     731 non-null    int64  \n",
      " 7   workingday  731 non-null    int64  \n",
      " 8   weathersit  731 non-null    int64  \n",
      " 9   temp        731 non-null    float64\n",
      " 10  atemp       731 non-null    float64\n",
      " 11  hum         731 non-null    float64\n",
      " 12  windspeed   731 non-null    float64\n",
      " 13  casual      731 non-null    int64  \n",
      " 14  registered  731 non-null    int64  \n",
      " 15  cnt         731 non-null    int64  \n",
      "dtypes: float64(4), int64(11), object(1)\n",
      "memory usage: 91.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>247</td>\n",
       "      <td>1867</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.255046</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>644</td>\n",
       "      <td>2451</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>159</td>\n",
       "      <td>1182</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0          1  2011-01-01       1   0     1        0        6           0   \n",
       "1          2  2011-01-02       1   0     1        0        0           0   \n",
       "2          3  2011-01-03       1   0     1        0        1           1   \n",
       "3          4  2011-01-04       1   0     1        0        2           1   \n",
       "4          5  2011-01-05       1   0     1        0        3           1   \n",
       "..       ...         ...     ...  ..   ...      ...      ...         ...   \n",
       "726      727  2012-12-27       1   1    12        0        4           1   \n",
       "727      728  2012-12-28       1   1    12        0        5           1   \n",
       "728      729  2012-12-29       1   1    12        0        6           0   \n",
       "729      730  2012-12-30       1   1    12        0        0           0   \n",
       "730      731  2012-12-31       1   1    12        0        1           1   \n",
       "\n",
       "     weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0             2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1             2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2             1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3             1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4             1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "..          ...       ...       ...       ...        ...     ...         ...   \n",
       "726           2  0.254167  0.226642  0.652917   0.350133     247        1867   \n",
       "727           2  0.253333  0.255046  0.590000   0.155471     644        2451   \n",
       "728           2  0.253333  0.242400  0.752917   0.124383     159        1182   \n",
       "729           1  0.255833  0.231700  0.483333   0.350754     364        1432   \n",
       "730           2  0.215833  0.223487  0.577500   0.154846     439        2290   \n",
       "\n",
       "      cnt  \n",
       "0     985  \n",
       "1     801  \n",
       "2    1349  \n",
       "3    1562  \n",
       "4    1600  \n",
       "..    ...  \n",
       "726  2114  \n",
       "727  3095  \n",
       "728  1341  \n",
       "729  1796  \n",
       "730  2729  \n",
       "\n",
       "[731 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "data = pd.read_csv('day.csv')\n",
    "\n",
    "print(data.info())\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ydata = data['cnt'][:100] # on prend que les 100 premiers car sinon les algorithmes sont longs\n",
    "Xdata = data.iloc[:100,4:13]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Xdata,Ydata, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On implémente Ridge normal dans un premier temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 0.7419434028166703)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "meilleur_score = max(cross_val_score(Ridge(alpha = 50), X_train, Y_train, cv=5))\n",
    "terme_regularisation = 1\n",
    "                      \n",
    "for i in range(0,50):\n",
    "    if max(cross_val_score(Ridge(alpha = i), X_train, Y_train, cv=5)) > meilleur_score :\n",
    "        terme_regularisation = i\n",
    "        meilleur_score = max(cross_val_score(Ridge(alpha = i), X_train, Y_train, cv=5))\n",
    "\n",
    "(terme_regularisation, meilleur_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prediction\n",
      "3224.2345416950157\n"
     ]
    }
   ],
   "source": [
    "def reg_Ridge(X_train, Y_train, terme_regularisation):\n",
    "    # regresion linéaire Ridge : theta = (lamda*I + X'*X)^-1 * X' * Y\n",
    "    I = np.identity(X_train.shape[1])\n",
    "    C = (X_train.T).dot(X_train) + I * terme_regularisation\n",
    "    Cinv = np.linalg.inv(C)\n",
    "    theta = Cinv.dot(X_train.T)\n",
    "    theta = theta.dot(Y_train)\n",
    "    return theta\n",
    "\n",
    "\n",
    "def prediction_ridge(X_test,theta):\n",
    "    Y_pred = X_test.dot(theta)\n",
    "    return Y_pred\n",
    "\n",
    "Y_pred = prediction_ridge(X_test, reg_Ridge(X_train,Y_train, terme_regularisation))\n",
    "#La constante de régularisation doit être déterminé par validation croissée, mais nous la fixons à 50 pour le moment\n",
    "print('Erreur de prediction')\n",
    "print(np.linalg.norm(Y_pred-Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prediction\n",
      "2431.968001056232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train,Y_train)\n",
    "Y_pred = ridge.predict(X_test)\n",
    "print('Erreur de prediction')\n",
    "print(np.linalg.norm(Y_pred-Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On implémente un kernel ridge avec le produit scalaire comme noyau dans un premier temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod(x,y):\n",
    "    (n,) = x.shape\n",
    "    if n ==1 :\n",
    "        return x.dot(y.T)\n",
    "    else:\n",
    "        return x.T.dot(y)\n",
    "\n",
    "def kernel_Ridge(X_train, Y_train, terme_regularisation, kernel):\n",
    "    # kernel Ridge : theta = (Gram + lamda*I)^-1 * Y\n",
    "    I = np.identity(X_train.shape[0])\n",
    "    Gram = np.identity(X_train.shape[0])\n",
    "    for i in range(0, X_train.shape[0]): #on remplit la matrice de Gram\n",
    "        for j in range(0, X_train.shape[0]):\n",
    "            Gram[i][j] = kernel(X_train.iloc[i,:],X_train.iloc[j,:])\n",
    "    C = Gram + I * terme_regularisation\n",
    "    Cinv = np.linalg.inv(C)\n",
    "    theta = Cinv.dot(Y_train)\n",
    "    return theta\n",
    "    \n",
    "theta_kernel = kernel_Ridge(X_train, Y_train, terme_regularisation, lambda x, y: prod(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prediction avec le noyau produit scalaire\n",
      "3224.2345416950147\n"
     ]
    }
   ],
   "source": [
    "def prediction_kernel_ridge(X_train, X_test,theta, kernel): #f(X) = SUM(alpha_i * kernel(X,X_i))\n",
    "    vect = np.zeros((X_test.shape[0], X_train.shape[0]))\n",
    "    for i in range(0, X_test.shape[0]):\n",
    "        for j in range(0, X_train.shape[0]):\n",
    "            vect[i][j] = kernel(X_test.iloc[i,:],X_train.iloc[j,:])\n",
    "    Y_pred = vect.dot(theta)\n",
    "    return Y_pred\n",
    "\n",
    "Y_pred_kernel = prediction_kernel_ridge(X_train, X_test, theta_kernel, lambda x, y: prod(x,y))\n",
    "print('Erreur de prediction avec le noyau produit scalaire')\n",
    "print(np.linalg.norm(Y_pred_kernel-Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons de changer de noyau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prediction avec le noyau polynomial\n",
      "4046.608640758396\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def poly(x,y):\n",
    "    (n,) = x.shape\n",
    "    if n ==1 :\n",
    "        return (x.dot(y.T))**2\n",
    "    else:\n",
    "        return (x.T.dot(y))**2\n",
    "\n",
    "theta_kernel_autre_noyau = kernel_Ridge(X_train, Y_train, terme_regularisation, lambda x, y: poly(x,y))\n",
    "\n",
    "Y_pred_kernel = prediction_kernel_ridge(X_train, X_test, theta_kernel_autre_noyau, lambda x, y: poly(x,y))\n",
    "print('Erreur de prediction avec le noyau polynomial')\n",
    "print(np.linalg.norm(Y_pred_kernel-Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prediction avec le noyau rbf\n",
      "4509.651438130885\n"
     ]
    }
   ],
   "source": [
    "def rbf(x,y):\n",
    "    return math.exp(-0.01*(np.linalg.norm(x-y))**2)\n",
    "\n",
    "theta_kernel_autre_noyau = kernel_Ridge(X_train, Y_train, terme_regularisation, lambda x, y: rbf(x,y))\n",
    "\n",
    "Y_pred_kernel = prediction_kernel_ridge(X_train, X_test, theta_kernel_autre_noyau, lambda x, y: rbf(x,y))\n",
    "print('Erreur de prediction avec le noyau rbf')\n",
    "print(np.linalg.norm(Y_pred_kernel-Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visiblement, le kernel polynomiale et rbf mène à du surapprentissage pour cette base de données. Les modèles sont trop complexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MKL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme mettra quelques minutes à s'exécuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 37.91721187,   7.49371592,  28.01489967, -17.57842916,\n",
       "         27.02293074,  -2.57144889,  25.39367606,  -7.50137824,\n",
       "        -18.99545085, -12.48916562,   3.20282238,  -8.12635168,\n",
       "         -5.9281379 , -22.19589725,  19.93501875, -25.67600551,\n",
       "         27.79766261,   6.67023826,   9.57665496,  14.98693319,\n",
       "         -3.9461173 ,  15.21781355,  18.28669763,  -9.0787792 ,\n",
       "         15.51838958,  37.04043398,  14.84362344, -29.1281169 ,\n",
       "         -4.21550685,   8.11309148, -10.88098716,  -7.92293181,\n",
       "         25.67885926,  24.48024704,  12.08087527,   0.46370743,\n",
       "        -14.60973032, -21.72501733,   2.91479948,  20.42448728,\n",
       "         33.55258783,  35.24740556, -34.44623396, -67.24570735,\n",
       "          4.77238588, -20.74234569,  13.6364869 ,  -9.86882779,\n",
       "        -10.96939349,  -1.9399629 ,  -1.97927299,   2.90634328,\n",
       "        -10.7033133 , -11.12434291, -29.98610797,  -3.06680866,\n",
       "         23.25322478, -21.69655387, -10.47993807,   0.25030337,\n",
       "          2.63461869,  21.37583824,  28.67465367,  18.87763576,\n",
       "          3.03728603,  13.62606194,  64.40878101,  25.84926785,\n",
       "          8.18441253,  34.44479672]),\n",
       " [0.723878031288243, 0.6585761812160295, 0.20561616997008988])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def L2_norm_MKL(X_train, Y_train, X_test, epsilon,terme_regularisation,liste_kernel, n) :\n",
    "    Fk = []\n",
    "    beta = [1/len(liste_kernel) for i in range(len(liste_kernel))]\n",
    "    alpha = 0\n",
    "    for t in range(n):\n",
    "        \n",
    "        alpha_prime = alpha\n",
    "        new_kernel = lambda x, y: beta[0] * liste_kernel[0](x,y) + beta[1] * liste_kernel[1](x,y) + beta[2] * liste_kernel[2](x,y)\n",
    "        alpha = kernel_Ridge(X_train, Y_train, terme_regularisation, new_kernel)\n",
    "        \n",
    "        if np.linalg.norm(alpha - alpha_prime) < epsilon :\n",
    "            return alpha, beta\n",
    "        \n",
    "        Fk = [prediction_kernel_ridge(X_train, X_test, alpha, lambda x, y: liste_kernel[i](x,y)) for i in range(len(liste_kernel))]\n",
    "        \n",
    "        for i in range(len(liste_kernel)):\n",
    "            beta[i] = np.linalg.norm(Fk[i])**(2/3) / math.sqrt(np.linalg.norm(Fk[0]) ** (4/3) + np.linalg.norm(Fk[1]) ** (4/3) + np.linalg.norm(Fk[2]) ** (4/3))\n",
    "    \n",
    "    return alpha, beta\n",
    "\n",
    "liste_kernel = [lambda x, y: prod(x,y), lambda x, y: poly(x,y), lambda x, y: rbf(x,y)]\n",
    "alpha, beta = L2_norm_MKL(X_train, Y_train, X_test, 0.05,terme_regularisation, liste_kernel, 10)\n",
    "\n",
    "alpha, beta\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prediction kernel MKL\n",
      "3202.2479041789525\n"
     ]
    }
   ],
   "source": [
    "new_kernel = lambda x, y: beta[0] * liste_kernel[0](x,y) + beta[1] * liste_kernel[1](x,y) + beta[2] * liste_kernel[2](x,y)\n",
    "Y_pred_kernel = prediction_kernel_ridge(X_train, X_test, alpha, new_kernel)\n",
    "\n",
    "print('Erreur de prediction kernel MKL')\n",
    "print(np.linalg.norm(Y_pred_kernel-Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinaison Uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prediction kernel uniforme\n",
      "3356.7057228461586\n"
     ]
    }
   ],
   "source": [
    "kernel_uniforme = lambda x, y: (1/3) * liste_kernel[0](x,y) + (1/3) * liste_kernel[1](x,y) + (1/3)  * liste_kernel[2](x,y)\n",
    "theta_kernel_uniforme = kernel_Ridge(X_train, Y_train, terme_regularisation, kernel_uniforme)\n",
    "Y_pred_kernel = prediction_kernel_ridge(X_train, X_test, theta_kernel_uniforme, kernel_uniforme)\n",
    "\n",
    "print('Erreur de prediction kernel uniforme')\n",
    "print(np.linalg.norm(Y_pred_kernel-Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les meilleurs résultats sont obtenus avec la méthode MKL, suivi de la regression Ridge avec un kernel produit scalaire et enfin la combinaison uniforme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Kitchen Sinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %Training\n",
    "def Random_feature(X_train, Y_train, X_test, terme_regularisation):\n",
    "    W = np.random.normal(0,0.2,(X_train.shape[0],X_train.shape[1]))\n",
    "    phi = np.concatenate([np.cos(X_train.dot(W.T)), np.sin(X_train.dot(W.T))],axis = 1)\n",
    "    I = np.identity(X_train.shape[0])\n",
    "    C = phi.dot(phi.T) + I * terme_regularisation\n",
    "    Cinv = np.linalg.pinv(C)\n",
    "    theta = Cinv.dot(Y_train)\n",
    "    \n",
    "# %Testing\n",
    "\n",
    "    phi_test = np.concatenate([np.cos(X_test.dot(W.T)), np.sin(X_test.dot(W.T))],axis = 1)\n",
    "    K = phi_test.dot(phi.T)\n",
    "    return K.dot(theta)\n",
    "\n",
    "Y_pred_random = Random_feature(X_train, Y_train, X_test, terme_regularisation)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prediction Random Kitchen Sinks\n",
      "2604.7711217395704\n"
     ]
    }
   ],
   "source": [
    "print('Erreur de prediction Random Kitchen Sinks')\n",
    "print(np.linalg.norm(Y_pred_random-Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methode de Nystrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 70)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = int(X_train.shape[0] / 3)\n",
    "\n",
    "def Nystrom(X_train, kernel, m):\n",
    "    np.random.randint(low=1, high=X_train.shape[0], size=m)\n",
    "    C = np.zeros((X_train.shape[0], m))\n",
    "    for i in range(0, X_train.shape[0]):\n",
    "        for j in range(0,m):\n",
    "            C[i][j] = kernel(X_train.iloc[i,:],X_train.iloc[j,:])\n",
    "\n",
    "    W = np.zeros((m, m))\n",
    "    for i in range(0, m):\n",
    "        for j in range(0,m):\n",
    "            W[i][j] = kernel(X_train.iloc[i,:],X_train.iloc[j,:])\n",
    "\n",
    "    Winv = np.linalg.pinv(W)\n",
    "    G_nystrom = Winv.dot(C.T)\n",
    "    G_nystrom = C.dot(G_nystrom)\n",
    "\n",
    "    return G_nystrom\n",
    "\n",
    "G_nystrom = Nystrom(X_train, lambda x, y: prod(x,y), m)\n",
    "G_nystrom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_Ridge_avec_Nystrom(X_train, Y_train, terme_regularisation, kernel, Gram):\n",
    "    # kernel Ridge : theta = (Gram + lamda*I)^-1 * Y\n",
    "    I = np.identity(X_train.shape[0])\n",
    "    C = Gram + I * terme_regularisation\n",
    "    Cinv = np.linalg.inv(C)\n",
    "    theta = Cinv.dot(Y_train)\n",
    "    return theta\n",
    "\n",
    "theta_nystrom = kernel_Ridge_avec_Nystrom(X_train, Y_train, terme_regularisation, lambda x, y: prod(x,y), Nystrom(X_train, lambda x, y: prod(x,y), m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur de prediction avec Nystrom\n",
      "3224.234541699633\n"
     ]
    }
   ],
   "source": [
    "Y_pred_nystrom = prediction_kernel_ridge(X_train, X_test, theta_nystrom, lambda x, y: prod(x,y))\n",
    "print('Erreur de prediction avec Nystrom')\n",
    "print(np.linalg.norm(Y_pred_nystrom-Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'approximation de Nyström est meilleure dans notre cas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
